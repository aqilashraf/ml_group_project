# -*- coding: utf-8 -*-
"""Streamlit coding.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12XdcPZF47_TwqYkJkL6HLM3wZ6lcKfJ8
"""

import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.linear_model import LinearRegression

# --------------------------------------------------
# PAGE CONFIG
# --------------------------------------------------
st.set_page_config(
    page_title="Predicting and Analysing Air Pollution Index in Malaysia ",
    layout="wide"
)

st.title("üå´Ô∏è Air Pollution Index (API) Prediction App")
st.write("Exploratory Analysis, Model Development & Prediction")

# --------------------------------------------------
# LOAD DATA
# --------------------------------------------------
@st.cache_data
def load_data():
    return pd.read_csv("new_data.csv")

data = load_data()

# --------------------------------------------------
# PREPROCESSING & FEATURE ENGINEERING
# --------------------------------------------------
data = data.drop_duplicates()
data["air_pollution_concentration"].fillna(
    data["air_pollution_concentration"].median(), inplace=True
)

le = LabelEncoder()
data["air_pollutant_type"] = le.fit_transform(data["air_pollutant_type"])

limits = {
    "PM 2.5": 15,
    "PM 10": 45,
    "NO2": 0.02,
    "O3": 0.05,
    "CO": 4,
    "SO2": 0.02
}

pollutant_map = dict(zip(le.transform(le.classes_), le.classes_))

data["normalized_conc"] = data.apply(
    lambda row: row["air_pollution_concentration"] /
    limits[pollutant_map[row["air_pollutant_type"]]],
    axis=1
)

monthly_api = (
    data.groupby("month")["normalized_conc"]
    .mean()
    .reset_index()
    .rename(columns={"normalized_conc": "API_value"})
)

data = data.merge(monthly_api, on="month", how="left")

# Interaction features
data["traffic_emissions"] = data["car_registrations_y"] * data["normalized_conc"]
data["traffic_fire"] = data["car_registrations_y"] * data["fire_frp"]
data["ipi_pollution"] = data["ipi_index"] * data["normalized_conc"]
data["ipi_firefrp"] = data["ipi_index"] * data["fire_frp"]

features = [
    "avg_rainfall_mm",
    "fire_brightness",
    "fire_frp",
    "consumption",
    "normalized_conc",
    "traffic_emissions",
    "traffic_fire",
    "ipi_pollution",
    "ipi_firefrp"
]

X = data[features]
y = data["API_value"]

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y, test_size=0.2, random_state=42
)

# --------------------------------------------------
# SIDEBAR MENU
# --------------------------------------------------
menu = st.sidebar.selectbox(
    "Select Section",
    [
        "EDA",
        "Model Development",
        "Model Evaluation",
        "Model Comparison",
        "Best Model & Prediction"
    ]
)

# --------------------------------------------------
# EDA SECTION
# --------------------------------------------------
if menu == "EDA":
    st.subheader("üìä Exploratory Data Analysis")

    numeric_cols = data.select_dtypes(include=np.number).columns

    selected_feature = st.selectbox(
        "Select a feature to visualize",
        numeric_cols
    )

    fig, ax = plt.subplots()
    ax.hist(data[selected_feature], bins=30)
    ax.set_title(f"Distribution of {selected_feature}")
    st.pyplot(fig)

    st.write("Summary Statistics")
    st.dataframe(data[numeric_cols].describe())

# --------------------------------------------------
# MODEL DEVELOPMENT
# --------------------------------------------------
if menu == "Model Development (with Tuning)":
    st.subheader("‚öôÔ∏è Model Development & Hyperparameter Tuning")

    model_choice = st.selectbox(
        "Select Model",
        ["Decision Tree (Tuned)", "Random Forest", "Gradient Boosting", "Linear Regression (Tuned)"]
    )

    # -------------------------------
    # Decision Tree (Tuned)
    # -------------------------------
    if model_choice == "Decision Tree (Tuned)":
        param_grid = {
            "max_depth": [None, 5, 10, 15],
            "min_samples_split": [2, 5, 10],
            "min_samples_leaf": [1, 2, 4]
        }

        grid = GridSearchCV(
            DecisionTreeRegressor(random_state=42),
            param_grid,
            cv=5,
            scoring="r2",
            n_jobs=-1
        )

        grid.fit(X_train, y_train)
        model = grid.best_estimator_

        st.write("üîç Best Parameters:", grid.best_params_)

    # -------------------------------
    # Random Forest
    # -------------------------------
    elif model_choice == "Random Forest":
        model = RandomForestRegressor(
            n_estimators=200,
            random_state=42
        )
        model.fit(X_train, y_train)

    # -------------------------------
    # Gradient Boosting
    # -------------------------------
    elif model_choice == "Gradient Boosting":
        model = GradientBoostingRegressor(random_state=42)
        model.fit(X_train, y_train)

    # -------------------------------
    # Linear Regression (Tuned)
    # -------------------------------
    else:
        poly = PolynomialFeatures(degree=3)
        X_poly = poly.fit_transform(X_train)
        X_poly_test = poly.transform(X_test)

        param_grid = {"alpha": [0.001, 0.01, 0.1, 1, 10]}
        grid = GridSearchCV(
            Lasso(max_iter=3000),
            param_grid,
            cv=5,
            scoring="r2"
        )

        grid.fit(X_poly, y_train)
        model = grid.best_estimator_

        st.write("üîç Best Alpha:", grid.best_params_["alpha"])

        y_pred = model.predict(X_poly_test)

            # Predictions
    if model_choice != "Linear Regression (Tuned)":
        y_pred = model.predict(X_test)

    fig, ax = plt.subplots()
    ax.scatter(y_test, y_pred, alpha=0.6)
    ax.plot([y_test.min(), y_test.max()],
            [y_test.min(), y_test.max()], "r--")
    ax.set_xlabel("Actual")
    ax.set_ylabel("Predicted")
    ax.set_title("Actual vs Predicted")
    st.pyplot(fig)

# --------------------------------------------------
# MODEL EVALUATION
# --------------------------------------------------
if menu == "Model Evaluation":
    st.subheader("üìà Model Evaluation")

    models = {
        "Decision Tree": DecisionTreeRegressor(random_state=42),
        "Random Forest": RandomForestRegressor(n_estimators=200, random_state=42),
        "Gradient Boosting": GradientBoostingRegressor(random_state=42),
        "Linear Regression": LinearRegression()
    }

    results = []

    for name, model in models.items():
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)

        results.append({
            "Model": name,
            "MAE": mean_absolute_error(y_test, y_pred),
            "RMSE": np.sqrt(mean_squared_error(y_test, y_pred)),
            "R2": r2_score(y_test, y_pred),
            "CV R2 Mean": cross_val_score(model, X_train, y_train, cv=5, scoring="r2").mean()
        })

    results_df = pd.DataFrame(results)
    st.dataframe(results_df)

# --------------------------------------------------
# MODEL COMPARISON
# --------------------------------------------------
if menu == "Model Comparison":
    st.subheader("üèÜ Model Comparison")

    comparison_metric = st.selectbox(
        "Select comparison metric",
        ["R2", "RMSE", "MAE", "CV R2 Mean"]
    )

    results_df = pd.DataFrame({
    'Model': ['Decision Tree', 'Random Forest', 'Gradient Boosting', 'Linear Regression'],
    'MAE': [mae_dt, mae_rf, mae_gb, mae_lr],
    'MSE': [mse_dt, mse_rf, mse_gb, mse_lr],
    'RMSE': [rmse_dt, rmse_rf, rmse_gb, rmse_lr],
    'R2 Score': [r2_dt, r2_rf, r2_gb, r2_lr],
    'CV R2 Mean': [cv_dt.mean(), cv_rf.mean(), cv_gb.mean(), cv_lr.mean()],
    'CV R2 Std Dev': [std_dev_dt, std_dev_rf, std_dev_gb, std_dev_lr]
}
    })

    fig, ax = plt.subplots()
    ax.bar(results_df["Model"], results_df[comparison_metric])
    ax.set_title(f"Model Comparison based on {comparison_metric}")
    st.pyplot(fig)

# --------------------------------------------------
# BEST MODEL & PREDICTION
# --------------------------------------------------
if menu == "Best Model & Prediction":
    st.subheader("‚úÖ Best Model: Gradient Boosting")

    st.write("""
    Based on evaluation metrics:
    - Highest CV R¬≤
    - Strong generalization
    - Stable performance

    **Gradient Boosting is selected as the final model**
    """)

    gb_model = GradientBoostingRegressor(random_state=42)
    gb_model.fit(X_train, y_train)

    st.subheader("üîÆ Predict API Index")

    user_inputs = []
    for col in features:
        user_inputs.append(
            st.number_input(col, value=float(data[col].mean()))
        )

    input_df = pd.DataFrame([user_inputs], columns=features)
    input_scaled = scaler.transform(input_df)

    prediction = gb_model.predict(input_scaled)[0]

    st.success(f"### Predicted API Value: **{prediction:.4f}**")